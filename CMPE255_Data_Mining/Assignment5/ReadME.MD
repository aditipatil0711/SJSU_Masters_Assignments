Assignment5

Link to Medium Article: https://addy07.medium.com/mastering-datas-arcana-unveiling-the-impact-of-auto-eda-and-automl-on-data-preparation-and-cb5670c4a818


<a target="_blank" href="https://addy07.medium.com/mastering-datas-arcana-unveiling-the-impact-of-auto-eda-and-automl-on-data-preparation-and-cb5670c4a818">



# EDA, Data Preparation, and AutoML on Kaggle Datasets

This repository contains detailed exploratory data analysis (EDA), data preparation, and processing workflows for a variety of Kaggle datasets. Each dataset represents a different type of data, ranging from tabular to video, and demonstrates comprehensive data cleaning, feature processing, and machine learning modeling using AutoML techniques.

## Solution Overview

The goal of this project was to conduct EDA, data preparation, and processing on popular Kaggle datasets that required cleaning. The datasets chosen represent a wide array of data types including tabular, time series, spatio-temporal, image, audio, video, and graph data. The project ensured a mix of imbalanced and balanced datasets and involved detailed preprocessing, clustering, anomaly detection, data imputation, feature processing, and feature selection. AutoML platforms were utilized to build various machine learning models, including ensemble models.

## Datasets

Below are the links to the Kaggle datasets used for this project:

1. **Tabular Dataset**: [NYC Taxi Trip Duration](https://www.kaggle.com/c/nyc-taxi-trip-duration)
2. **Time Series Dataset**: [Link to Dataset](#)
3. **Spatio-Temporal Dataset**: [Link to Dataset](#)
4. **Image Dataset**: [Link to Dataset](#)
5. **Audio Dataset**: [Link to Dataset](#)
6. **Video Dataset**: [Link to Dataset](#)
7. **Graph Dataset**: [Link to Dataset](#)

## Colab Notebooks

For detailed analyses and processing steps, refer to the Colab notebooks linked below:

- **Tabular Data**: [Colab Notebook](#)
- **Time Series Data**: [Colab Notebook](#)
- **Spatio-Temporal Data**: [Colab Notebook](#)
- **Image Data**: [Colab Notebook](#)
- **Audio Data**: [Colab Notebook](#)
- **Video Data**: [Colab Notebook](#)
- **Graph Data**: [Colab Notebook](#)

## Medium Article

For a comprehensive understanding of the process, challenges, and insights gained from this project, read our Medium article:

- **Mastering Data's Arcana**: [Medium Article](#)

## Project Structure

Each folder in the repository corresponds to a dataset type and contains the following:

- Jupyter notebook with EDA, preprocessing, and modeling steps
- A `requirements.txt` file with all necessary Python packages
- Additional resources like images, models, and CSV files used or generated during the project

## How to Use

To replicate the analysis and model building:

1. Clone the repository.
2. Install the dependencies using `pip install -r requirements.txt`.
3. Run the Jupyter notebooks in Colab or your local setup.

## Contributions

Contributions to this project are welcome. Please fork the repository and submit a pull request with your proposed changes.

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

